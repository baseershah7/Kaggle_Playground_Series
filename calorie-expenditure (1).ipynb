{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceacf3da",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-30T10:50:28.994555Z",
     "iopub.status.busy": "2025-05-30T10:50:28.994310Z",
     "iopub.status.idle": "2025-05-30T10:50:30.483132Z",
     "shell.execute_reply": "2025-05-30T10:50:30.482066Z"
    },
    "papermill": {
     "duration": 1.497737,
     "end_time": "2025-05-30T10:50:30.485088",
     "exception": false,
     "start_time": "2025-05-30T10:50:28.987351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/calorie-expenditure/__results__.html\n",
      "/kaggle/input/calorie-expenditure/cat_oof_preds.csv\n",
      "/kaggle/input/calorie-expenditure/__notebook__.ipynb\n",
      "/kaggle/input/calorie-expenditure/cat_test_preds.csv\n",
      "/kaggle/input/calorie-expenditure/__output__.json\n",
      "/kaggle/input/calorie-expenditure/custom.css\n",
      "/kaggle/input/calorie-expenditure/models/cat16.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat15.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat6.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat18.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat8.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat7.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat19.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat3.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat14.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat1.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat17.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat11.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat10.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat12.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat13.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat4.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat20.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat2.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat5.cbm\n",
      "/kaggle/input/calorie-expenditure/models/cat9.cbm\n",
      "/kaggle/input/calorie-expenditure/catboost_info/test_error.tsv\n",
      "/kaggle/input/calorie-expenditure/catboost_info/learn_error.tsv\n",
      "/kaggle/input/calorie-expenditure/catboost_info/catboost_training.json\n",
      "/kaggle/input/calorie-expenditure/catboost_info/time_left.tsv\n",
      "/kaggle/input/calorie-expenditure/catboost_info/learn/events.out.tfevents\n",
      "/kaggle/input/calorie-expenditure/catboost_info/test/events.out.tfevents\n",
      "/kaggle/input/playground-series-s5e5/sample_submission.csv\n",
      "/kaggle/input/playground-series-s5e5/train.csv\n",
      "/kaggle/input/playground-series-s5e5/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a69472c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T10:50:30.499134Z",
     "iopub.status.busy": "2025-05-30T10:50:30.498666Z",
     "iopub.status.idle": "2025-05-30T10:50:30.504383Z",
     "shell.execute_reply": "2025-05-30T10:50:30.503592Z"
    },
    "papermill": {
     "duration": 0.014446,
     "end_time": "2025-05-30T10:50:30.506463",
     "exception": false,
     "start_time": "2025-05-30T10:50:30.492017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "splits=10\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f6a8828",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T10:50:30.524900Z",
     "iopub.status.busy": "2025-05-30T10:50:30.524414Z",
     "iopub.status.idle": "2025-05-30T10:50:31.569118Z",
     "shell.execute_reply": "2025-05-30T10:50:31.568522Z"
    },
    "papermill": {
     "duration": 1.052815,
     "end_time": "2025-05-30T10:50:31.570441",
     "exception": false,
     "start_time": "2025-05-30T10:50:30.517626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/playground-series-s5e5/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s5e5/test.csv')\n",
    "samp_sub = pd.read_csv('/kaggle/input/playground-series-s5e5/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d1c5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T10:50:31.582307Z",
     "iopub.status.busy": "2025-05-30T10:50:31.581866Z",
     "iopub.status.idle": "2025-05-30T10:50:32.783624Z",
     "shell.execute_reply": "2025-05-30T10:50:32.783019Z"
    },
    "papermill": {
     "duration": 1.208992,
     "end_time": "2025-05-30T10:50:32.784968",
     "exception": false,
     "start_time": "2025-05-30T10:50:31.575976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import warnings\n",
    "def cv_score(X, y, model_dict, n_splits=5, seed=42):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    scores = {name: [] for name in model_dict.keys()}\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y), 1):\n",
    "        # Split original data\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train_orig, y_valid_orig = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        # 1. Box-Cox Transformation (Per Fold)\n",
    "        y_train_bc, lambda_fold = stats.boxcox(y_train_orig + 1)  # Add 1 to handle zeros\n",
    "        y_train_bc = pd.Series(y_train_bc, index=y_train_orig.index)\n",
    "\n",
    "        # # 2. AutoFeat Engineering (Per Fold)\n",
    "        # af = AutoFeatRegressor()\n",
    "        # with warnings.catch_warnings():\n",
    "        #     warnings.simplefilter(\"ignore\")\n",
    "        #     X_train_fe = af.fit_transform(X_train, y_train_bc)\n",
    "        #     X_valid_fe = af.transform(X_valid)\n",
    "\n",
    "        # 3. Model Training & Validation\n",
    "        for name, model in model_dict.items():\n",
    "            reg = clone(model)\n",
    "            \n",
    "            if isinstance(reg, cat.CatBoostRegressor):\n",
    "                train_pool = Pool(X_train, y_train_bc)\n",
    "                reg.fit(train_pool, verbose=0)\n",
    "                preds_bc = reg.predict(X_valid)\n",
    "            else:\n",
    "                reg.fit(X_train, y_train_bc)\n",
    "                preds_bc = reg.predict(X_valid)\n",
    "\n",
    "            # Inverse transformation\n",
    "            preds = inv_boxcox(preds_bc, lambda_fold) - 1  # Subtract added constant\n",
    "            preds = np.clip(preds, 1e-6, None)\n",
    "            \n",
    "            # Calculate RMSLE\n",
    "            rmsle = np.sqrt(mean_squared_log_error(y_valid_orig, preds))\n",
    "            scores[name].append(rmsle)\n",
    "            print(f\"Fold {fold} | {name} | RMSLE: {rmsle:.5f}\")\n",
    "\n",
    "    # Calculate final scores\n",
    "    print(\"\\n=== Final Scores ===\")\n",
    "    for name in model_dict:\n",
    "        avg_score = np.mean(scores[name])\n",
    "        std_score = np.std(scores[name])\n",
    "        print(f\"{name}: {avg_score:.5f} ± {std_score:.5f}\")\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86509491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T10:50:32.796269Z",
     "iopub.status.busy": "2025-05-30T10:50:32.795960Z",
     "iopub.status.idle": "2025-05-30T10:50:32.799131Z",
     "shell.execute_reply": "2025-05-30T10:50:32.798636Z"
    },
    "papermill": {
     "duration": 0.009854,
     "end_time": "2025-05-30T10:50:32.800169",
     "exception": false,
     "start_time": "2025-05-30T10:50:32.790315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install autofeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5929905a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T10:50:32.810956Z",
     "iopub.status.busy": "2025-05-30T10:50:32.810764Z",
     "iopub.status.idle": "2025-05-30T10:50:37.833586Z",
     "shell.execute_reply": "2025-05-30T10:50:37.833008Z"
    },
    "papermill": {
     "duration": 5.029729,
     "end_time": "2025-05-30T10:50:37.834990",
     "exception": false,
     "start_time": "2025-05-30T10:50:32.805261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from autofeat import AutoFeatRegressor\n",
    "from scipy import stats\n",
    "from scipy.special import inv_boxcox\n",
    "\n",
    "sex_mapping = {\n",
    "    'male':0,\n",
    "    'female':1\n",
    "}\n",
    "train['Sex'] = train['Sex'].map(sex_mapping)\n",
    "test['Sex'] = test['Sex'].map(sex_mapping)\n",
    "X = train.drop(columns=['Calories'])\n",
    "y = train['Calories']\n",
    "y_bc, lambda_ = stats.boxcox(y)\n",
    "y_bc = pd.Series(y_bc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b902892b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T10:50:37.846969Z",
     "iopub.status.busy": "2025-05-30T10:50:37.846219Z",
     "iopub.status.idle": "2025-05-30T10:50:48.809728Z",
     "shell.execute_reply": "2025-05-30T10:50:48.809133Z"
    },
    "papermill": {
     "duration": 10.970526,
     "end_time": "2025-05-30T10:50:48.811100",
     "exception": false,
     "start_time": "2025-05-30T10:50:37.840574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "from catboost import Pool\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "import shap\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.013746281229599575,\n",
    "    'depth': 10,\n",
    "    'l2_leaf_reg': 2.6989912450312117,\n",
    "    'random_strength': 2.1007809924141934,\n",
    "    'grow_policy': 'SymmetricTree',\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'iterations': 2249,\n",
    "    'border_count': 100,\n",
    "    'has_time': True,\n",
    "    'subsample': 0.9297145525388769,\n",
    "}\n",
    "model = cat.CatBoostRegressor(random_state=seed, verbose=0, task_type='GPU', **params)\n",
    "# model.fit(X_train_new, y_bc)\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values = explainer.shap_values(X_train_new)\n",
    "\n",
    "# importance_features = pd.DataFrame(\n",
    "#     {'feature':X_train_new.columns,\n",
    "#     'importance': np.abs(shap_values).mean(0)}\n",
    "# ).sort_values('importance', ascending=False)\n",
    "# top_features = importance_features.head(5)['feature'].tolist()\n",
    "model_dict = {\n",
    "    # 'xgb': xgb.XGBRegressor(random_state=seed),\n",
    "    # 'lgb': lgb.LGBMRegressor(random_state=seed, verbosity=0),\n",
    "    # 'etr': ExtraTreesRegressor(random_state=seed, n_jobs=-1),\n",
    "    'cat': cat.CatBoostRegressor(random_state=seed, verbose=0,task_type='GPU', **params),\n",
    "    # 'hgb': HistGradientBoostingRegressor(random_state=seed)}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f72f5206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T10:50:48.822500Z",
     "iopub.status.busy": "2025-05-30T10:50:48.822044Z",
     "iopub.status.idle": "2025-05-30T10:50:48.825313Z",
     "shell.execute_reply": "2025-05-30T10:50:48.824832Z"
    },
    "papermill": {
     "duration": 0.009866,
     "end_time": "2025-05-30T10:50:48.826363",
     "exception": false,
     "start_time": "2025-05-30T10:50:48.816497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_train_new = pd.read_csv('/kaggle/input/calorie-expenditure/X_train_new_2step.csv')\n",
    "# X_test_new = pd.read_csv('/kaggle/input/calorie-expenditure/X_test_new_2step.csv')\n",
    "# cols = ['Sex',\n",
    "#  'Duration',\n",
    "#  'Heart_Rate',\n",
    "#  '1/Duration',\n",
    "#  'Age*Duration**2',\n",
    "#  'log(Duration)/Duration',\n",
    "#  'sqrt(Age)*log(Duration)',\n",
    "#  'sqrt(Age)*Heart_Rate**3']\n",
    "# X_train_new = X_train_new[cols]\n",
    "# X_test_new = X_test_new[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd9c7f4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T10:50:48.837103Z",
     "iopub.status.busy": "2025-05-30T10:50:48.836895Z",
     "iopub.status.idle": "2025-05-30T10:50:48.928130Z",
     "shell.execute_reply": "2025-05-30T10:50:48.927503Z"
    },
    "papermill": {
     "duration": 0.098168,
     "end_time": "2025-05-30T10:50:48.929500",
     "exception": false,
     "start_time": "2025-05-30T10:50:48.831332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    # df['bmr_proxy'] = (\n",
    "    #     (df['Weight'] * 10) + \n",
    "    #     (df['Height'] * 6.25) - \n",
    "    #     (df['Age'] * 5) + \n",
    "    #     np.where(df['Sex'] == 0, 5, -161)  # Vectorized conditional\n",
    "    # )\n",
    "    # # 2. Cardiovascular Efficiency Score\n",
    "    # df['cardio_eff'] = df['Heart_Rate'] * df['Duration'] / (df['Age']**0.5)\n",
    "\n",
    "    # # 3. Thermal Metabolic Load\n",
    "    # df['thermal_load'] = (df['Body_Temp'] - 36.5) * df['Duration']\n",
    "\n",
    "    # 4. Body Mass Index Squared Interaction\n",
    "    df['bmi_hr'] = (df['Weight']/(df['Height']/100)**2) * df['Heart_Rate']\n",
    "\n",
    "    # 5. Age-Weighted Intensity\n",
    "    # df['age_intensity'] = (220 - df['Age'] - df['Heart_Rate']) * df['Duration']\n",
    "\n",
    "    # # 6. Metabolic Equivalent (MET) Estimate\n",
    "    # df['met_estimate'] = (df['Heart_Rate'] * df['Body_Temp']) / (df['Age']**0.3)\n",
    "\n",
    "    # # 7. Oxygen Consumption Proxy\n",
    "    # df['vo2_max_proxy'] = (df['Heart_Rate'] * df['Duration']) / (df['Weight']**0.5)\n",
    "\n",
    "    # # 8. Gender-Specific Metabolic Rate\n",
    "    # df['sex_metabolic'] = df['Sex'] * (df['bmr_proxy'] / df['Age'])\n",
    "\n",
    "    # # 9. Body Surface Area (DuBois formula)\n",
    "    # df['bsa'] = 0.007184 * (df['Height']**0.725) * (df['Weight']**0.425)\n",
    "\n",
    "    # # 10. Heart Rate Reserve\n",
    "    # df['hr_reserve'] = (df['Heart_Rate'] / (220 - df['Age'])) * df['Duration']\n",
    "\n",
    "    # # 11. Thermic Effect of Exercise\n",
    "    # df['tee'] = np.log1p(df['Duration']) * (df['Body_Temp'] - 36.5) * df['Weight']\n",
    "\n",
    "    # # 12. Power-to-Weight Ratio\n",
    "    # df['power_weight'] = (df['Duration'] * df['Heart_Rate']) / df['Weight']\n",
    "\n",
    "    # # 13. Age-Decay Adjusted Calories\n",
    "    # df['age_decay'] = np.exp(-df['Age']/50) * df['Duration'] * df['Heart_Rate']\n",
    "\n",
    "    # # 14. Body Composition Index\n",
    "    # df['bci'] = (df['Height']/100) / (df['Weight']**0.3) * df['Heart_Rate']\n",
    "\n",
    "    # # 15. Cumulative Exertion\n",
    "    # df['cumulative_exertion'] = (df['Heart_Rate'] * df['Body_Temp']) / (\n",
    "    # df['Weight'] * (df['Age']**0.2))\n",
    "    return df.copy()\n",
    "\n",
    "X_new = feature_engineering(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94b47614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T10:50:48.941315Z",
     "iopub.status.busy": "2025-05-30T10:50:48.941086Z",
     "iopub.status.idle": "2025-05-30T10:50:48.987091Z",
     "shell.execute_reply": "2025-05-30T10:50:48.986408Z"
    },
    "papermill": {
     "duration": 0.053269,
     "end_time": "2025-05-30T10:50:48.988172",
     "exception": false,
     "start_time": "2025-05-30T10:50:48.934903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def generate_oof_predictions(X, y, model_dict, cv_folds=5, seed=42, categorical_features=None):\n",
    "    n_samples = len(X)\n",
    "    oof_predictions = pd.DataFrame(index=range(n_samples))\n",
    "    \n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    transformations = {\n",
    "        **{f'cat{i}': 'log1p' for i in range(1, 11)},\n",
    "        **{f'xgb{i}': 'log1p' for i in range(1, 11)},\n",
    "        **{f'cat{i}': 'yeo_johnson' for i in range(11, 16)},\n",
    "        **{f'xgb{i}': 'yeo_johnson' for i in range(11, 16)}\n",
    "    }\n",
    "    \n",
    "    print(\"Starting Out-of-Fold Prediction Generation...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for model_name, base_model in model_dict.items():\n",
    "        print(f\"\\nProcessing {model_name} with {transformations.get(model_name, 'log1p')} transformation:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        oof_preds = np.zeros(n_samples)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "            print(f\"  Fold {fold + 1}/{cv_folds}... \", end=\"\")\n",
    "            \n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            transformation_type = transformations.get(model_name, 'log1p')\n",
    "            \n",
    "            if transformation_type == 'log1p':\n",
    "                y_train_transformed = np.log1p(y_train)\n",
    "                y_val_transformed = np.log1p(y_val)\n",
    "            elif transformation_type == 'yeo_johnson':\n",
    "                yj_transformer = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "                y_train_transformed = yj_transformer.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "                y_val_transformed = yj_transformer.transform(y_val.values.reshape(-1, 1)).ravel()\n",
    "            \n",
    "            # UNIVERSAL MODEL CLONING\n",
    "            model = clone(base_model)\n",
    "            \n",
    "            if model_name.startswith('cat'):\n",
    "                # CatBoost with Pool\n",
    "                train_pool = Pool(X_train, y_train_transformed, cat_features=categorical_features)\n",
    "                val_pool = Pool(X_val, y_val_transformed, cat_features=categorical_features)\n",
    "                \n",
    "                model.set_params(verbose=False)\n",
    "                model.fit(train_pool, eval_set=val_pool, verbose=False)\n",
    "                val_preds_transformed = model.predict(val_pool)\n",
    "                \n",
    "            elif model_name.startswith('xgb'):\n",
    "                # XGBoost with sklearn interface (arrays)\n",
    "                model.set_params(verbose=False)\n",
    "                model.fit(\n",
    "                    X_train.values, \n",
    "                    y_train_transformed,\n",
    "                    eval_set=[(X_val.values, y_val_transformed)],\n",
    "                    verbose=False\n",
    "                )\n",
    "                val_preds_transformed = model.predict(X_val.values)\n",
    "            \n",
    "            # Inverse transformation\n",
    "            if transformation_type == 'log1p':\n",
    "                val_preds = np.expm1(val_preds_transformed)\n",
    "            elif transformation_type == 'yeo_johnson':\n",
    "                val_preds = yj_transformer.inverse_transform(val_preds_transformed.reshape(-1, 1)).ravel()\n",
    "            \n",
    "            val_preds = np.maximum(val_preds, 0)\n",
    "            oof_preds[val_idx] = val_preds\n",
    "            \n",
    "            fold_score = np.sqrt(mean_squared_log_error(y_val, val_preds))\n",
    "            fold_scores.append(fold_score)\n",
    "            print(f\"RMSLE: {fold_score:.6f}\")\n",
    "        \n",
    "        oof_predictions[model_name] = oof_preds\n",
    "        overall_score = np.sqrt(mean_squared_log_error(y, oof_preds))\n",
    "        print(f\"  Overall {model_name} RMSLE: {overall_score:.6f}\")\n",
    "        print(f\"  Fold RMSLE: {np.mean(fold_scores):.6f} ± {np.std(fold_scores):.6f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"OOF Prediction Generation Complete!\")\n",
    "    return oof_predictions\n",
    "\n",
    "\n",
    "def generate_test_predictions(X_train, y_train, X_test, model_dict, categorical_features=None, save_dir=\"/kaggle/working/models\"):\n",
    "    test_predictions = pd.DataFrame(index=range(len(X_test)))\n",
    "    transformations = {\n",
    "        **{f'cat{i}': 'log1p' for i in range(1, 11)},\n",
    "        **{f'xgb{i}': 'log1p' for i in range(1, 11)},\n",
    "        **{f'cat{i}': 'yeo_johnson' for i in range(11, 16)},\n",
    "        **{f'xgb{i}': 'yeo_johnson' for i in range(11, 16)}\n",
    "    }\n",
    "    \n",
    "    print(\"Starting Test Prediction Generation...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    for model_name, base_model in model_dict.items():\n",
    "        transformation_type = transformations.get(model_name, 'log1p')\n",
    "        print(f\"\\nTraining {model_name} with {transformation_type} transformation:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Apply transformation\n",
    "        if transformation_type == 'log1p':\n",
    "            y_transformed = np.log1p(y_train)\n",
    "            transformer = None\n",
    "        elif transformation_type == 'yeo_johnson':\n",
    "            yj_transformer = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "            y_transformed = yj_transformer.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "            transformer = yj_transformer\n",
    "        \n",
    "        # UNIVERSAL MODEL CLONING\n",
    "        model = clone(base_model)\n",
    "        \n",
    "        if model_name.startswith('cat'):\n",
    "            # CatBoost with Pool\n",
    "            train_pool = Pool(X_train, y_transformed, cat_features=categorical_features)\n",
    "            test_pool = Pool(X_test, cat_features=categorical_features)\n",
    "            \n",
    "            model.set_params(verbose=False)\n",
    "            model.fit(train_pool, verbose=False)\n",
    "            \n",
    "            # Save model\n",
    "            model_path = os.path.join(save_dir, f\"{model_name}.cbm\")\n",
    "            model.save_model(model_path)\n",
    "            test_preds_transformed = model.predict(test_pool)\n",
    "            \n",
    "        elif model_name.startswith('xgb'):\n",
    "            # XGBoost with sklearn interface (arrays)\n",
    "            model.set_params(verbose=False)\n",
    "            model.fit(X_train.values, y_transformed)\n",
    "            \n",
    "            # Save model\n",
    "            model_path = os.path.join(save_dir, f\"{model_name}.json\")\n",
    "            model.save_model(model_path)\n",
    "            test_preds_transformed = model.predict(X_test.values)\n",
    "        \n",
    "        print(f\"  Saved model to: {model_path}\")\n",
    "        \n",
    "        # Inverse transformation\n",
    "        if transformation_type == 'log1p':\n",
    "            test_preds = np.expm1(test_preds_transformed)\n",
    "        elif transformation_type == 'yeo_johnson':\n",
    "            test_preds = transformer.inverse_transform(test_preds_transformed.reshape(-1, 1)).ravel()\n",
    "        \n",
    "        test_preds = np.maximum(test_preds, 0)\n",
    "        test_predictions[model_name] = test_preds\n",
    "        print(f\"  Predictions generated - Mean: {test_preds.mean():.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Test Prediction Generation Complete!\")\n",
    "    return test_predictions\n",
    "\n",
    "model_dict = {\n",
    "    # Top 10 Performers (Best RMSLE scores)\n",
    "    'cat1': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.013746, 'depth': 10, 'l2_leaf_reg': 2.698991,\n",
    "        'random_strength': 2.10078, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 2249,\n",
    "        'border_count': 100, 'subsample': 0.92971, 'min_data_in_leaf': 69, 'random_state': seed+1\n",
    "    }),\n",
    "    'cat2': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.015832, 'depth': 11, 'l2_leaf_reg': 0.349602,\n",
    "        'random_strength': 1.64188, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 1942,\n",
    "        'border_count': 101, 'subsample': 0.93569, 'min_data_in_leaf': 83, 'random_state': seed+2\n",
    "    }),\n",
    "    'cat3': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.006420, 'depth': 13, 'l2_leaf_reg': 0.004398,\n",
    "        'random_strength': 2.75674, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 2964,\n",
    "        'border_count': 74, 'subsample': 0.89261, 'min_data_in_leaf': 31, 'random_state': seed+3\n",
    "    }),\n",
    "    'cat4': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.013490, 'depth': 11, 'l2_leaf_reg': 0.000440,\n",
    "        'random_strength': 1.66404, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 2962,\n",
    "        'border_count': 79, 'subsample': 0.89010, 'min_data_in_leaf': 44, 'random_state': seed+4\n",
    "    }),\n",
    "    'cat5': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.018602, 'depth': 13, 'l2_leaf_reg': 1.412277,\n",
    "        'random_strength': 1.19449, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 1366,\n",
    "        'border_count': 103, 'subsample': 0.95810, 'min_data_in_leaf': 94, 'random_state': seed+5\n",
    "    }),\n",
    "    'cat6': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.012350, 'depth': 12, 'l2_leaf_reg': 0.182027,\n",
    "        'random_strength': 1.13882, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 1765,\n",
    "        'border_count': 100, 'subsample': 0.87510, 'min_data_in_leaf': 79, 'random_state': seed+6\n",
    "    }),\n",
    "    'cat7': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.006722, 'depth': 12, 'l2_leaf_reg': 0.000298,\n",
    "        'random_strength': 2.72937, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 2832,\n",
    "        'border_count': 94, 'subsample': 0.84665, 'min_data_in_leaf': 60, 'random_state': seed+7\n",
    "    }),\n",
    "    'cat8': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.008025, 'depth': 13, 'l2_leaf_reg': 0.002097,\n",
    "        'random_strength': 2.76358, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 2665,\n",
    "        'border_count': 70, 'subsample': 0.86397, 'min_data_in_leaf': 41, 'random_state': seed+8\n",
    "    }),\n",
    "    'cat9': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.011477, 'depth': 13, 'l2_leaf_reg': 5.256055,\n",
    "        'random_strength': 0.42451, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 1855,\n",
    "        'border_count': 110, 'subsample': 0.90999, 'min_data_in_leaf': 30, 'random_state': seed+9\n",
    "    }),\n",
    "    'cat10': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.007692, 'depth': 12, 'l2_leaf_reg': 0.044905,\n",
    "        'random_strength': 0.77312, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 2947,\n",
    "        'border_count': 89, 'subsample': 0.86828, 'min_data_in_leaf': 29, 'random_state': seed+10\n",
    "    }),\n",
    "\n",
    "    # Diverse Models (Different hyperparameter configurations)\n",
    "    'cat11': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.149922, 'depth': 4, 'l2_leaf_reg': 0.000954,\n",
    "        'random_strength': 0.13577, 'grow_policy': 'Depthwise',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 1713,\n",
    "        'border_count': 82, 'subsample': 0.96043, 'min_data_in_leaf': 26, 'random_state': seed+11\n",
    "    }),\n",
    "    'cat12': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.009778, 'depth': 5, 'l2_leaf_reg': 0.003320,\n",
    "        'random_strength': 1.57431, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bayesian', 'iterations': 1584,\n",
    "        'border_count': 87, 'min_data_in_leaf': 36, 'random_state': seed+12\n",
    "    }),\n",
    "    'cat13': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.019906, 'depth': 13, 'l2_leaf_reg': 0.457056,\n",
    "        'random_strength': 1.79601, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 2202,\n",
    "        'border_count': 110, 'subsample': 0.96648, 'min_data_in_leaf': 37, 'random_state': seed+13\n",
    "    }),\n",
    "    'cat14': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.033327, 'depth': 9, 'l2_leaf_reg': 0.000170,\n",
    "        'random_strength': 1.82267, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 2617,\n",
    "        'border_count': 83, 'subsample': 0.88803, 'min_data_in_leaf': 29, 'random_state': seed+14\n",
    "    }),\n",
    "    'cat15': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.031065, 'depth': 4, 'l2_leaf_reg': 3.520481,\n",
    "        'random_strength': 0.77641, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 1369,\n",
    "        'border_count': 127, 'subsample': 0.97896, 'min_data_in_leaf': 68, 'random_state': seed+15\n",
    "    }),\n",
    "    'cat16': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.036289, 'depth': 12, 'l2_leaf_reg': 3.208846,\n",
    "        'random_strength': 1.81915, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 2466,\n",
    "        'border_count': 98, 'subsample': 0.80658, 'min_data_in_leaf': 46, 'random_state': seed+16\n",
    "    }),\n",
    "    'cat17': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.015127, 'depth': 12, 'l2_leaf_reg': 0.044913,\n",
    "        'random_strength': 0.88674, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 1314,\n",
    "        'border_count': 89, 'has_time': True, 'subsample': 0.86067,\n",
    "        'min_data_in_leaf': 77, 'random_state': seed+17\n",
    "    }),\n",
    "    'cat18': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.007834, 'depth': 12, 'l2_leaf_reg': 0.000188,\n",
    "        'random_strength': 1.19145, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 2969,\n",
    "        'border_count': 76, 'subsample': 0.88556, 'min_data_in_leaf': 42, 'random_state': seed+18\n",
    "    }),\n",
    "    'cat19': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.005942, 'depth': 13, 'l2_leaf_reg': 3.519287,\n",
    "        'random_strength': 2.20966, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 2734,\n",
    "        'border_count': 67, 'subsample': 0.90607, 'min_data_in_leaf': 31, 'random_state': seed+19\n",
    "    }),\n",
    "    'cat20': CatBoostRegressor(**{\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': 0.008074, 'depth': 12, 'l2_leaf_reg': 0.000154,\n",
    "        'random_strength': 1.42529, 'grow_policy': 'SymmetricTree',\n",
    "        'bootstrap_type': 'Bernoulli', 'iterations': 2940,\n",
    "        'border_count': 76, 'subsample': 0.89114, 'min_data_in_leaf': 34, 'random_state': seed+20\n",
    "    })\n",
    "}\n",
    "\n",
    "def create_model_dict(seed=seed):\n",
    "    # Top 20 trials sorted by score (ascending)\n",
    "    top_trials = [\n",
    "        {'learning_rate': 0.005083, 'max_depth': 10, 'min_child_weight': 0.1395, 'subsample': 0.8310,\n",
    "         'colsample_bytree': 0.8060, 'colsample_bylevel': 0.8634, 'colsample_bynode': 0.9274,\n",
    "         'reg_alpha': 0.000462, 'reg_lambda': 0.0476, 'gamma': 0.007818, 'max_delta_step': 6.8812,\n",
    "         'n_estimators': 2870, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 87,\n",
    "         'scale_pos_weight': 2.6815, 'max_cat_to_onehot': 1},  # Trial 106 (best)\n",
    "\n",
    "        {'learning_rate': 0.010725, 'max_depth': 9, 'min_child_weight': 0.1139, 'subsample': 0.5774,\n",
    "         'colsample_bytree': 0.7203, 'colsample_bylevel': 0.7391, 'colsample_bynode': 0.9827,\n",
    "         'reg_alpha': 3.37e-6, 'reg_lambda': 2.93e-5, 'gamma': 8.45e-6, 'max_delta_step': 9.7342,\n",
    "         'n_estimators': 4548, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 212,\n",
    "         'scale_pos_weight': 1.8312, 'max_cat_to_onehot': 5},  # Trial 121\n",
    "\n",
    "        {'learning_rate': 0.012735, 'max_depth': 8, 'min_child_weight': 0.2303, 'subsample': 0.7543,\n",
    "         'colsample_bytree': 0.8886, 'colsample_bylevel': 0.9938, 'colsample_bynode': 0.7659,\n",
    "         'reg_alpha': 0.000156, 'reg_lambda': 0.21299, 'gamma': 0.01833, 'max_delta_step': 4.8201,\n",
    "         'n_estimators': 2625, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 110,\n",
    "         'scale_pos_weight': 0.1081, 'max_cat_to_onehot': 1},  # Trial 123\n",
    "\n",
    "        {'learning_rate': 0.006451, 'max_depth': 10, 'min_child_weight': 0.19999, 'subsample': 0.8157,\n",
    "         'colsample_bytree': 0.8856, 'colsample_bylevel': 0.9826, 'colsample_bynode': 0.9802,\n",
    "         'reg_alpha': 0.000186, 'reg_lambda': 0.25328, 'gamma': 0.013416, 'max_delta_step': 6.9531,\n",
    "         'n_estimators': 1871, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 164,\n",
    "         'scale_pos_weight': 0.1679, 'max_cat_to_onehot': 2},  # Trial 102\n",
    "\n",
    "        {'learning_rate': 0.008894, 'max_depth': 7, 'min_child_weight': 0.1165, 'subsample': 0.7397,\n",
    "         'colsample_bytree': 0.9203, 'colsample_bylevel': 0.5501, 'colsample_bynode': 0.9911,\n",
    "         'reg_alpha': 9.26e-6, 'reg_lambda': 0.001512, 'gamma': 0.008014, 'max_delta_step': 6.3884,\n",
    "         'n_estimators': 4156, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 264,\n",
    "         'scale_pos_weight': 2.5502, 'max_cat_to_onehot': 6},  # Trial 114\n",
    "\n",
    "        {'learning_rate': 0.005829, 'max_depth': 8, 'min_child_weight': 0.2082, 'subsample': 0.7023,\n",
    "         'colsample_bytree': 0.7377, 'colsample_bylevel': 0.8288, 'colsample_bynode': 0.8138,\n",
    "         'reg_alpha': 0.02487, 'reg_lambda': 1.708e-6, 'gamma': 0.000311, 'max_delta_step': 6.3249,\n",
    "         'n_estimators': 4626, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 186,\n",
    "         'scale_pos_weight': 2.6929, 'max_cat_to_onehot': 3},  # Trial 58\n",
    "\n",
    "        {'learning_rate': 0.014913, 'max_depth': 12, 'min_child_weight': 0.5018, 'subsample': 0.8225,\n",
    "         'colsample_bytree': 0.7975, 'colsample_bylevel': 0.9770, 'colsample_bynode': 0.7928,\n",
    "         'reg_alpha': 1.2734, 'reg_lambda': 0.0189, 'gamma': 0.001216, 'max_delta_step': 3.2869,\n",
    "         'n_estimators': 2822, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 99,\n",
    "         'scale_pos_weight': 2.9850, 'max_cat_to_onehot': 4},  # Trial 76\n",
    "\n",
    "        {'learning_rate': 0.010725, 'max_depth': 9, 'min_child_weight': 0.7080, 'subsample': 0.8153,\n",
    "         'colsample_bytree': 0.8771, 'colsample_bylevel': 0.9459, 'colsample_bynode': 0.8879,\n",
    "         'reg_alpha': 2.4606, 'reg_lambda': 0.7910, 'gamma': 0.01128, 'max_delta_step': 0.7271,\n",
    "         'n_estimators': 2696, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 272,\n",
    "         'scale_pos_weight': 3.9623, 'max_cat_to_onehot': 3},  # Trial 82\n",
    "\n",
    "        {'learning_rate': 0.007009, 'max_depth': 14, 'min_child_weight': 0.1542, 'subsample': 0.8970,\n",
    "         'colsample_bytree': 0.9043, 'colsample_bylevel': 0.6083, 'colsample_bynode': 0.7258,\n",
    "         'reg_alpha': 0.3723, 'reg_lambda': 1.7508, 'gamma': 1.729e-8, 'max_delta_step': 7.1540,\n",
    "         'n_estimators': 3778, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 217,\n",
    "         'scale_pos_weight': 2.8116, 'max_cat_to_onehot': 6},  # Trial 134\n",
    "\n",
    "        {'learning_rate': 0.012865, 'max_depth': 7, 'min_child_weight': 0.1083, 'subsample': 0.5875,\n",
    "         'colsample_bytree': 0.9857, 'colsample_bylevel': 0.8953, 'colsample_bynode': 0.9458,\n",
    "         'reg_alpha': 1.2417, 'reg_lambda': 2.51e-6, 'gamma': 2.448e-7, 'max_delta_step': 6.8302,\n",
    "         'n_estimators': 2780, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 97,\n",
    "         'scale_pos_weight': 5.6313, 'max_cat_to_onehot': 2},  # Trial 108\n",
    "\n",
    "        # Remaining 10 models for Yeo-Johnson and Box-Cox (next best trials)\n",
    "        {'learning_rate': 0.009934, 'max_depth': 9, 'min_child_weight': 0.1139, 'subsample': 0.5774,\n",
    "         'colsample_bytree': 0.7203, 'colsample_bylevel': 0.7391, 'colsample_bynode': 0.9827,\n",
    "         'reg_alpha': 3.37e-6, 'reg_lambda': 2.93e-5, 'gamma': 8.45e-6, 'max_delta_step': 9.7342,\n",
    "         'n_estimators': 4548, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 212,\n",
    "         'scale_pos_weight': 1.8312, 'max_cat_to_onehot': 5},  # Trial 121 (duplicate)\n",
    "\n",
    "        {'learning_rate': 0.011177, 'max_depth': 11, 'min_child_weight': 0.1664, 'subsample': 0.8599,\n",
    "         'colsample_bytree': 0.9581, 'colsample_bylevel': 0.9853, 'colsample_bynode': 0.9858,\n",
    "         'reg_alpha': 2.01e-5, 'reg_lambda': 1.0355, 'gamma': 0.00191, 'max_delta_step': 5.5203,\n",
    "         'n_estimators': 1446, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 131,\n",
    "         'scale_pos_weight': 0.8538, 'max_cat_to_onehot': 4},  # Trial 104\n",
    "\n",
    "        {'learning_rate': 0.019332, 'max_depth': 13, 'min_child_weight': 0.1840, 'subsample': 0.5284,\n",
    "         'colsample_bytree': 0.8355, 'colsample_bylevel': 0.9098, 'colsample_bynode': 0.9515,\n",
    "         'reg_alpha': 0.6159, 'reg_lambda': 0.0002, 'gamma': 3.847e-8, 'max_delta_step': 9.7405,\n",
    "         'n_estimators': 2048, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 178,\n",
    "         'scale_pos_weight': 0.4373, 'max_cat_to_onehot': 9},  # Trial 92\n",
    "\n",
    "        {'learning_rate': 0.014700, 'max_depth': 15, 'min_child_weight': 0.1905, 'subsample': 0.7315,\n",
    "         'colsample_bytree': 0.7554, 'colsample_bylevel': 0.9092, 'colsample_bynode': 0.9266,\n",
    "         'reg_alpha': 0.000625, 'reg_lambda': 5.7668, 'gamma': 0.00279, 'max_delta_step': 8.0438,\n",
    "         'n_estimators': 2464, 'booster': 'gbtree', 'grow_policy': 'lossguide', 'max_leaves': 88,\n",
    "         'max_bin': 79, 'scale_pos_weight': 7.8659, 'max_cat_to_onehot': 4},  # Trial 42\n",
    "\n",
    "        {'learning_rate': 0.008983, 'max_depth': 10, 'min_child_weight': 0.1133, 'subsample': 0.4776,\n",
    "         'colsample_bytree': 0.8145, 'colsample_bylevel': 0.8798, 'colsample_bynode': 0.7961,\n",
    "         'reg_alpha': 2.29e-7, 'reg_lambda': 0.000352, 'gamma': 0.005435, 'max_delta_step': 8.4745,\n",
    "         'n_estimators': 3965, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 418,\n",
    "         'scale_pos_weight': 3.1297, 'max_cat_to_onehot': 8},  # Trial 60\n",
    "\n",
    "        # Box-Cox models (assumed from next best trials)\n",
    "        {'learning_rate': 0.005486, 'max_depth': 11, 'min_child_weight': 0.1493, 'subsample': 0.5960,\n",
    "         'colsample_bytree': 0.8650, 'colsample_bylevel': 0.7675, 'colsample_bynode': 0.9718,\n",
    "         'reg_alpha': 0.00596, 'reg_lambda': 8.4105, 'gamma': 0.01176, 'max_delta_step': 8.5700,\n",
    "         'n_estimators': 2597, 'booster': 'gbtree', 'grow_policy': 'lossguide', 'max_leaves': 76,\n",
    "         'max_bin': 153, 'scale_pos_weight': 3.1721, 'max_cat_to_onehot': 6},  # Trial 38\n",
    "\n",
    "        {'learning_rate': 0.018357, 'max_depth': 11, 'min_child_weight': 0.6378, 'subsample': 0.8702,\n",
    "         'colsample_bytree': 0.6121, 'colsample_bylevel': 0.8548, 'colsample_bynode': 0.9953,\n",
    "         'reg_alpha': 1.249e-5, 'reg_lambda': 0.00208, 'gamma': 4.866e-5, 'max_delta_step': 7.7886,\n",
    "         'n_estimators': 3118, 'booster': 'gbtree', 'grow_policy': 'lossguide', 'max_leaves': 70,\n",
    "         'max_bin': 98, 'scale_pos_weight': 1.9579, 'max_cat_to_onehot': 5},  # Trial 33\n",
    "\n",
    "        {'learning_rate': 0.021269, 'max_depth': 11, 'min_child_weight': 0.8516, 'subsample': 0.4435,\n",
    "         'colsample_bytree': 0.9108, 'colsample_bylevel': 0.7043, 'colsample_bynode': 0.9841,\n",
    "         'reg_alpha': 0.000257, 'reg_lambda': 2.2067, 'gamma': 0.000195, 'max_delta_step': 7.0162,\n",
    "         'n_estimators': 1841, 'booster': 'gbtree', 'grow_policy': 'lossguide', 'max_leaves': 66,\n",
    "         'max_bin': 205, 'scale_pos_weight': 4.6618, 'max_cat_to_onehot': 1},  # Trial 36\n",
    "\n",
    "        {'learning_rate': 0.029657, 'max_depth': 7, 'min_child_weight': 0.1266, 'subsample': 0.5557,\n",
    "         'colsample_bytree': 0.7108, 'colsample_bylevel': 0.9464, 'colsample_bynode': 0.7707,\n",
    "         'reg_alpha': 3.34e-6, 'reg_lambda': 0.02676, 'gamma': 1.256e-6, 'max_delta_step': 8.3364,\n",
    "         'n_estimators': 1408, 'booster': 'gbtree', 'grow_policy': 'depthwise', 'max_bin': 116,\n",
    "         'scale_pos_weight': 2.9827, 'max_cat_to_onehot': 1},  # Trial 30\n",
    "\n",
    "        {'learning_rate': 0.010821, 'max_depth': 7, 'min_child_weight': 1.0747, 'subsample': 0.9333,\n",
    "         'colsample_bytree': 0.7553, 'colsample_bylevel': 0.5955, 'colsample_bynode': 0.8278,\n",
    "         'reg_alpha': 5.10e-6, 'reg_lambda': 0.00452, 'gamma': 1.484e-6, 'max_delta_step': 4.6020,\n",
    "         'n_estimators': 4936, 'booster': 'gbtree', 'grow_policy': 'lossguide', 'max_leaves': 116,\n",
    "         'max_bin': 221, 'scale_pos_weight': 4.6267, 'max_cat_to_onehot': 5}  # Trial 16\n",
    "    ]\n",
    "\n",
    "    model_dict = {}\n",
    "    for i in range(20):\n",
    "        params = top_trials[i].copy()\n",
    "        params['random_state'] = seed + i\n",
    "        params['tree_method'] = 'gpu_hist'\n",
    "        model_name = f'xgb{i+1}'\n",
    "        model_dict[model_name] = XGBRegressor(**params)\n",
    "    \n",
    "    return model_dict\n",
    "xgb_dict = create_model_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fa6c6a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T10:50:48.998706Z",
     "iopub.status.busy": "2025-05-30T10:50:48.998475Z",
     "iopub.status.idle": "2025-05-30T10:50:49.009532Z",
     "shell.execute_reply": "2025-05-30T10:50:49.008885Z"
    },
    "papermill": {
     "duration": 0.017497,
     "end_time": "2025-05-30T10:50:49.010616",
     "exception": false,
     "start_time": "2025-05-30T10:50:48.993119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X_new.drop(columns=['id', 'bmi_hr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5c2a135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T10:50:49.021208Z",
     "iopub.status.busy": "2025-05-30T10:50:49.021002Z",
     "iopub.status.idle": "2025-05-30T14:16:12.723543Z",
     "shell.execute_reply": "2025-05-30T14:16:12.722837Z"
    },
    "papermill": {
     "duration": 12323.725673,
     "end_time": "2025-05-30T14:16:12.741179",
     "exception": false,
     "start_time": "2025-05-30T10:50:49.015506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Out-of-Fold Prediction Generation...\n",
      "============================================================\n",
      "\n",
      "Processing xgb1 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060168\n",
      "  Fold 2/10... RMSLE: 0.058601\n",
      "  Fold 3/10... RMSLE: 0.061183\n",
      "  Fold 4/10... RMSLE: 0.058832\n",
      "  Fold 5/10... RMSLE: 0.058925\n",
      "  Fold 6/10... RMSLE: 0.060135\n",
      "  Fold 7/10... RMSLE: 0.058774\n",
      "  Fold 8/10... RMSLE: 0.060595\n",
      "  Fold 9/10... RMSLE: 0.059483\n",
      "  Fold 10/10... RMSLE: 0.058339\n",
      "  Overall xgb1 RMSLE: 0.059511\n",
      "  Fold RMSLE: 0.059504 ± 0.000913\n",
      "\n",
      "Processing xgb2 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060568\n",
      "  Fold 2/10... RMSLE: 0.059353\n",
      "  Fold 3/10... RMSLE: 0.061883\n",
      "  Fold 4/10... RMSLE: 0.059152\n",
      "  Fold 5/10... RMSLE: 0.059599\n",
      "  Fold 6/10... RMSLE: 0.060506\n",
      "  Fold 7/10... RMSLE: 0.059332\n",
      "  Fold 8/10... RMSLE: 0.061196\n",
      "  Fold 9/10... RMSLE: 0.060153\n",
      "  Fold 10/10... RMSLE: 0.058979\n",
      "  Overall xgb2 RMSLE: 0.060079\n",
      "  Fold RMSLE: 0.060072 ± 0.000912\n",
      "\n",
      "Processing xgb3 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060296\n",
      "  Fold 2/10... RMSLE: 0.058630\n",
      "  Fold 3/10... RMSLE: 0.061243\n",
      "  Fold 4/10... RMSLE: 0.058641\n",
      "  Fold 5/10... RMSLE: 0.059045\n",
      "  Fold 6/10... RMSLE: 0.060042\n",
      "  Fold 7/10... RMSLE: 0.058849\n",
      "  Fold 8/10... RMSLE: 0.060688\n",
      "  Fold 9/10... RMSLE: 0.059558\n",
      "  Fold 10/10... RMSLE: 0.058421\n",
      "  Overall xgb3 RMSLE: 0.059548\n",
      "  Fold RMSLE: 0.059541 ± 0.000930\n",
      "\n",
      "Processing xgb4 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060365\n",
      "  Fold 2/10... RMSLE: 0.058611\n",
      "  Fold 3/10... RMSLE: 0.061157\n",
      "  Fold 4/10... RMSLE: 0.058682\n",
      "  Fold 5/10... RMSLE: 0.059030\n",
      "  Fold 6/10... RMSLE: 0.060030\n",
      "  Fold 7/10... RMSLE: 0.058596\n",
      "  Fold 8/10... RMSLE: 0.060444\n",
      "  Fold 9/10... RMSLE: 0.059732\n",
      "  Fold 10/10... RMSLE: 0.058431\n",
      "  Overall xgb4 RMSLE: 0.059515\n",
      "  Fold RMSLE: 0.059508 ± 0.000914\n",
      "\n",
      "Processing xgb5 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060269\n",
      "  Fold 2/10... RMSLE: 0.058690\n",
      "  Fold 3/10... RMSLE: 0.061377\n",
      "  Fold 4/10... RMSLE: 0.058716\n",
      "  Fold 5/10... RMSLE: 0.059010\n",
      "  Fold 6/10... RMSLE: 0.059997\n",
      "  Fold 7/10... RMSLE: 0.058987\n",
      "  Fold 8/10... RMSLE: 0.060703\n",
      "  Fold 9/10... RMSLE: 0.059605\n",
      "  Fold 10/10... RMSLE: 0.058409\n",
      "  Overall xgb5 RMSLE: 0.059584\n",
      "  Fold RMSLE: 0.059576 ± 0.000934\n",
      "\n",
      "Processing xgb6 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060380\n",
      "  Fold 2/10... RMSLE: 0.058624\n",
      "  Fold 3/10... RMSLE: 0.061115\n",
      "  Fold 4/10... RMSLE: 0.058607\n",
      "  Fold 5/10... RMSLE: 0.058986\n",
      "  Fold 6/10... RMSLE: 0.060070\n",
      "  Fold 7/10... RMSLE: 0.058850\n",
      "  Fold 8/10... RMSLE: 0.060541\n",
      "  Fold 9/10... RMSLE: 0.059438\n",
      "  Fold 10/10... RMSLE: 0.058324\n",
      "  Overall xgb6 RMSLE: 0.059501\n",
      "  Fold RMSLE: 0.059494 ± 0.000918\n",
      "\n",
      "Processing xgb7 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060164\n",
      "  Fold 2/10... RMSLE: 0.059033\n",
      "  Fold 3/10... RMSLE: 0.061409\n",
      "  Fold 4/10... RMSLE: 0.059013\n",
      "  Fold 5/10... RMSLE: 0.059126\n",
      "  Fold 6/10... RMSLE: 0.060208\n",
      "  Fold 7/10... RMSLE: 0.058830\n",
      "  Fold 8/10... RMSLE: 0.060556\n",
      "  Fold 9/10... RMSLE: 0.059521\n",
      "  Fold 10/10... RMSLE: 0.058572\n",
      "  Overall xgb7 RMSLE: 0.059649\n",
      "  Fold RMSLE: 0.059643 ± 0.000860\n",
      "\n",
      "Processing xgb8 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.059832\n",
      "  Fold 2/10... RMSLE: 0.058621\n",
      "  Fold 3/10... RMSLE: 0.061011\n",
      "  Fold 4/10... RMSLE: 0.058898\n",
      "  Fold 5/10... RMSLE: 0.058639\n",
      "  Fold 6/10... RMSLE: 0.059978\n",
      "  Fold 7/10... RMSLE: 0.058808\n",
      "  Fold 8/10... RMSLE: 0.060432\n",
      "  Fold 9/10... RMSLE: 0.059250\n",
      "  Fold 10/10... RMSLE: 0.058133\n",
      "  Overall xgb8 RMSLE: 0.059367\n",
      "  Fold RMSLE: 0.059360 ± 0.000871\n",
      "\n",
      "Processing xgb9 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060309\n",
      "  Fold 2/10... RMSLE: 0.059197\n",
      "  Fold 3/10... RMSLE: 0.061784\n",
      "  Fold 4/10... RMSLE: 0.058956\n",
      "  Fold 5/10... RMSLE: 0.059265\n",
      "  Fold 6/10... RMSLE: 0.060388\n",
      "  Fold 7/10... RMSLE: 0.058942\n",
      "  Fold 8/10... RMSLE: 0.060836\n",
      "  Fold 9/10... RMSLE: 0.059668\n",
      "  Fold 10/10... RMSLE: 0.058655\n",
      "  Overall xgb9 RMSLE: 0.059808\n",
      "  Fold RMSLE: 0.059800 ± 0.000951\n",
      "\n",
      "Processing xgb10 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060279\n",
      "  Fold 2/10... RMSLE: 0.058659\n",
      "  Fold 3/10... RMSLE: 0.061092\n",
      "  Fold 4/10... RMSLE: 0.058864\n",
      "  Fold 5/10... RMSLE: 0.058867\n",
      "  Fold 6/10... RMSLE: 0.060117\n",
      "  Fold 7/10... RMSLE: 0.058789\n",
      "  Fold 8/10... RMSLE: 0.060516\n",
      "  Fold 9/10... RMSLE: 0.059710\n",
      "  Fold 10/10... RMSLE: 0.058330\n",
      "  Overall xgb10 RMSLE: 0.059529\n",
      "  Fold RMSLE: 0.059522 ± 0.000893\n",
      "\n",
      "Processing xgb11 with yeo_johnson transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060657\n",
      "  Fold 2/10... RMSLE: 0.058740\n",
      "  Fold 3/10... RMSLE: 0.061396\n",
      "  Fold 4/10... RMSLE: 0.058837\n",
      "  Fold 5/10... RMSLE: 0.059269\n",
      "  Fold 6/10... RMSLE: 0.060030\n",
      "  Fold 7/10... RMSLE: 0.059216\n",
      "  Fold 8/10... RMSLE: 0.060974\n",
      "  Fold 9/10... RMSLE: 0.059904\n",
      "  Fold 10/10... RMSLE: 0.058607\n",
      "  Overall xgb11 RMSLE: 0.059770\n",
      "  Fold RMSLE: 0.059763 ± 0.000938\n",
      "\n",
      "Processing xgb12 with yeo_johnson transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060589\n",
      "  Fold 2/10... RMSLE: 0.058607\n",
      "  Fold 3/10... RMSLE: 0.061166\n",
      "  Fold 4/10... RMSLE: 0.058879\n",
      "  Fold 5/10... RMSLE: 0.059047\n",
      "  Fold 6/10... RMSLE: 0.059964\n",
      "  Fold 7/10... RMSLE: 0.059023\n",
      "  Fold 8/10... RMSLE: 0.060699\n",
      "  Fold 9/10... RMSLE: 0.060032\n",
      "  Fold 10/10... RMSLE: 0.058668\n",
      "  Overall xgb12 RMSLE: 0.059674\n",
      "  Fold RMSLE: 0.059667 ± 0.000890\n",
      "\n",
      "Processing xgb13 with yeo_johnson transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.061643\n",
      "  Fold 2/10... RMSLE: 0.059781\n",
      "  Fold 3/10... RMSLE: 0.062447\n",
      "  Fold 4/10... RMSLE: 0.059827\n",
      "  Fold 5/10... RMSLE: 0.060252\n",
      "  Fold 6/10... RMSLE: 0.061044\n",
      "  Fold 7/10... RMSLE: 0.060248\n",
      "  Fold 8/10... RMSLE: 0.062040\n",
      "  Fold 9/10... RMSLE: 0.061055\n",
      "  Fold 10/10... RMSLE: 0.059728\n",
      "  Overall xgb13 RMSLE: 0.060814\n",
      "  Fold RMSLE: 0.060807 ± 0.000939\n",
      "\n",
      "Processing xgb14 with yeo_johnson transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060281\n",
      "  Fold 2/10... RMSLE: 0.058792\n",
      "  Fold 3/10... RMSLE: 0.061092\n",
      "  Fold 4/10... RMSLE: 0.058912\n",
      "  Fold 5/10... RMSLE: 0.059197\n",
      "  Fold 6/10... RMSLE: 0.060130\n",
      "  Fold 7/10... RMSLE: 0.059330\n",
      "  Fold 8/10... RMSLE: 0.060781\n",
      "  Fold 9/10... RMSLE: 0.059905\n",
      "  Fold 10/10... RMSLE: 0.058614\n",
      "  Overall xgb14 RMSLE: 0.059709\n",
      "  Fold RMSLE: 0.059703 ± 0.000818\n",
      "\n",
      "Processing xgb15 with yeo_johnson transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060951\n",
      "  Fold 2/10... RMSLE: 0.058841\n",
      "  Fold 3/10... RMSLE: 0.061388\n",
      "  Fold 4/10... RMSLE: 0.059032\n",
      "  Fold 5/10... RMSLE: 0.059337\n",
      "  Fold 6/10... RMSLE: 0.060299\n",
      "  Fold 7/10... RMSLE: 0.059367\n",
      "  Fold 8/10... RMSLE: 0.061156\n",
      "  Fold 9/10... RMSLE: 0.060293\n",
      "  Fold 10/10... RMSLE: 0.058778\n",
      "  Overall xgb15 RMSLE: 0.059952\n",
      "  Fold RMSLE: 0.059944 ± 0.000945\n",
      "\n",
      "Processing xgb16 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060303\n",
      "  Fold 2/10... RMSLE: 0.059043\n",
      "  Fold 3/10... RMSLE: 0.061380\n",
      "  Fold 4/10... RMSLE: 0.059375\n",
      "  Fold 5/10... RMSLE: 0.059129\n",
      "  Fold 6/10... RMSLE: 0.060434\n",
      "  Fold 7/10... RMSLE: 0.059227\n",
      "  Fold 8/10... RMSLE: 0.060969\n",
      "  Fold 9/10... RMSLE: 0.059886\n",
      "  Fold 10/10... RMSLE: 0.058660\n",
      "  Overall xgb16 RMSLE: 0.059847\n",
      "  Fold RMSLE: 0.059841 ± 0.000857\n",
      "\n",
      "Processing xgb17 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060549\n",
      "  Fold 2/10... RMSLE: 0.058933\n",
      "  Fold 3/10... RMSLE: 0.061503\n",
      "  Fold 4/10... RMSLE: 0.058971\n",
      "  Fold 5/10... RMSLE: 0.059280\n",
      "  Fold 6/10... RMSLE: 0.060377\n",
      "  Fold 7/10... RMSLE: 0.059412\n",
      "  Fold 8/10... RMSLE: 0.060871\n",
      "  Fold 9/10... RMSLE: 0.059820\n",
      "  Fold 10/10... RMSLE: 0.058538\n",
      "  Overall xgb17 RMSLE: 0.059832\n",
      "  Fold RMSLE: 0.059825 ± 0.000916\n",
      "\n",
      "Processing xgb18 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060335\n",
      "  Fold 2/10... RMSLE: 0.059130\n",
      "  Fold 3/10... RMSLE: 0.061598\n",
      "  Fold 4/10... RMSLE: 0.059243\n",
      "  Fold 5/10... RMSLE: 0.059362\n",
      "  Fold 6/10... RMSLE: 0.060512\n",
      "  Fold 7/10... RMSLE: 0.059216\n",
      "  Fold 8/10... RMSLE: 0.061034\n",
      "  Fold 9/10... RMSLE: 0.060027\n",
      "  Fold 10/10... RMSLE: 0.058731\n",
      "  Overall xgb18 RMSLE: 0.059925\n",
      "  Fold RMSLE: 0.059919 ± 0.000889\n",
      "\n",
      "Processing xgb19 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060832\n",
      "  Fold 2/10... RMSLE: 0.059193\n",
      "  Fold 3/10... RMSLE: 0.061667\n",
      "  Fold 4/10... RMSLE: 0.059293\n",
      "  Fold 5/10... RMSLE: 0.059708\n",
      "  Fold 6/10... RMSLE: 0.060704\n",
      "  Fold 7/10... RMSLE: 0.059611\n",
      "  Fold 8/10... RMSLE: 0.061038\n",
      "  Fold 9/10... RMSLE: 0.060214\n",
      "  Fold 10/10... RMSLE: 0.058896\n",
      "  Overall xgb19 RMSLE: 0.060122\n",
      "  Fold RMSLE: 0.060116 ± 0.000870\n",
      "\n",
      "Processing xgb20 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Fold 1/10... RMSLE: 0.060580\n",
      "  Fold 2/10... RMSLE: 0.059160\n",
      "  Fold 3/10... RMSLE: 0.061731\n",
      "  Fold 4/10... RMSLE: 0.059264\n",
      "  Fold 5/10... RMSLE: 0.059605\n",
      "  Fold 6/10... RMSLE: 0.060536\n",
      "  Fold 7/10... RMSLE: 0.059434\n",
      "  Fold 8/10... RMSLE: 0.060974\n",
      "  Fold 9/10... RMSLE: 0.060086\n",
      "  Fold 10/10... RMSLE: 0.058691\n",
      "  Overall xgb20 RMSLE: 0.060013\n",
      "  Fold RMSLE: 0.060006 ± 0.000895\n",
      "\n",
      "============================================================\n",
      "OOF Prediction Generation Complete!\n"
     ]
    }
   ],
   "source": [
    "xgb_oof_preds = generate_oof_predictions(\n",
    "        X=X, \n",
    "        y=y, \n",
    "        model_dict=xgb_dict,\n",
    "        cv_folds=10,\n",
    "        categorical_features=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b12b5a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:16:12.768864Z",
     "iopub.status.busy": "2025-05-30T14:16:12.768168Z",
     "iopub.status.idle": "2025-05-30T14:16:12.771403Z",
     "shell.execute_reply": "2025-05-30T14:16:12.770893Z"
    },
    "papermill": {
     "duration": 0.017633,
     "end_time": "2025-05-30T14:16:12.772453",
     "exception": false,
     "start_time": "2025-05-30T14:16:12.754820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# oof_preds = generate_oof_predictions(\n",
    "#         X=X, \n",
    "#         y=y, \n",
    "#         model_dict=model_dict,\n",
    "#         cv_folds=10,\n",
    "#         categorical_features=None\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a071ae36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:16:12.798612Z",
     "iopub.status.busy": "2025-05-30T14:16:12.798076Z",
     "iopub.status.idle": "2025-05-30T14:37:49.142791Z",
     "shell.execute_reply": "2025-05-30T14:37:49.141957Z"
    },
    "papermill": {
     "duration": 1296.372048,
     "end_time": "2025-05-30T14:37:49.157191",
     "exception": false,
     "start_time": "2025-05-30T14:16:12.785143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Test Prediction Generation...\n",
      "============================================================\n",
      "\n",
      "Training xgb1 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb1.json\n",
      "  Predictions generated - Mean: 88.1663\n",
      "\n",
      "Training xgb2 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb2.json\n",
      "  Predictions generated - Mean: 88.1759\n",
      "\n",
      "Training xgb3 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb3.json\n",
      "  Predictions generated - Mean: 88.1710\n",
      "\n",
      "Training xgb4 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb4.json\n",
      "  Predictions generated - Mean: 88.1664\n",
      "\n",
      "Training xgb5 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb5.json\n",
      "  Predictions generated - Mean: 88.1739\n",
      "\n",
      "Training xgb6 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb6.json\n",
      "  Predictions generated - Mean: 88.1745\n",
      "\n",
      "Training xgb7 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb7.json\n",
      "  Predictions generated - Mean: 88.1732\n",
      "\n",
      "Training xgb8 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb8.json\n",
      "  Predictions generated - Mean: 88.1723\n",
      "\n",
      "Training xgb9 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb9.json\n",
      "  Predictions generated - Mean: 88.1731\n",
      "\n",
      "Training xgb10 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb10.json\n",
      "  Predictions generated - Mean: 88.1785\n",
      "\n",
      "Training xgb11 with yeo_johnson transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb11.json\n",
      "  Predictions generated - Mean: 88.2076\n",
      "\n",
      "Training xgb12 with yeo_johnson transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb12.json\n",
      "  Predictions generated - Mean: 88.2054\n",
      "\n",
      "Training xgb13 with yeo_johnson transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb13.json\n",
      "  Predictions generated - Mean: 88.1962\n",
      "\n",
      "Training xgb14 with yeo_johnson transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb14.json\n",
      "  Predictions generated - Mean: 88.2046\n",
      "\n",
      "Training xgb15 with yeo_johnson transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb15.json\n",
      "  Predictions generated - Mean: 88.2070\n",
      "\n",
      "Training xgb16 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb16.json\n",
      "  Predictions generated - Mean: 88.1614\n",
      "\n",
      "Training xgb17 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb17.json\n",
      "  Predictions generated - Mean: 88.1761\n",
      "\n",
      "Training xgb18 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb18.json\n",
      "  Predictions generated - Mean: 88.1739\n",
      "\n",
      "Training xgb19 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb19.json\n",
      "  Predictions generated - Mean: 88.1748\n",
      "\n",
      "Training xgb20 with log1p transformation:\n",
      "--------------------------------------------------\n",
      "  Saved model to: /kaggle/working/models/xgb20.json\n",
      "  Predictions generated - Mean: 88.1657\n",
      "\n",
      "============================================================\n",
      "Test Prediction Generation Complete!\n"
     ]
    }
   ],
   "source": [
    "xgb_test_preds =  generate_test_predictions(X_train=X, y_train=y, model_dict=xgb_dict, X_test=test.drop(columns='id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24da556c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:37:49.184457Z",
     "iopub.status.busy": "2025-05-30T14:37:49.184218Z",
     "iopub.status.idle": "2025-05-30T14:37:49.187248Z",
     "shell.execute_reply": "2025-05-30T14:37:49.186735Z"
    },
    "papermill": {
     "duration": 0.017966,
     "end_time": "2025-05-30T14:37:49.188319",
     "exception": false,
     "start_time": "2025-05-30T14:37:49.170353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_preds.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6afc464b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:37:49.215498Z",
     "iopub.status.busy": "2025-05-30T14:37:49.215289Z",
     "iopub.status.idle": "2025-05-30T14:37:49.219116Z",
     "shell.execute_reply": "2025-05-30T14:37:49.218369Z"
    },
    "papermill": {
     "duration": 0.018773,
     "end_time": "2025-05-30T14:37:49.220233",
     "exception": false,
     "start_time": "2025-05-30T14:37:49.201460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def analyze_oof_predictions(oof_predictions, y_true):\n",
    "   \n",
    "#     results = {}\n",
    "    \n",
    "#     print(\"OOF Predictions Analysis:\")\n",
    "#     print(\"=\" * 40)\n",
    "    \n",
    "#     for col in oof_predictions.columns:\n",
    "#         try:\n",
    "#             score = np.sqrt(mean_squared_log_error(y_true, oof_predictions[col]))\n",
    "#             results[col] = {\n",
    "#                 'RMSLE': score,\n",
    "#                 'Mean_Pred': oof_predictions[col].mean(),\n",
    "#                 'Std_Pred': oof_predictions[col].std(),\n",
    "#                 'Min_Pred': oof_predictions[col].min(),\n",
    "#                 'Max_Pred': oof_predictions[col].max()\n",
    "#             }\n",
    "#             print(f\"{col}: RMSLE = {score:.6f}\")\n",
    "#         except ValueError as e:\n",
    "#             print(f\"{col}: Error calculating RMSLE - {e}\")\n",
    "#             results[col] = {\n",
    "#                 'RMSLE': np.nan,\n",
    "#                 'Mean_Pred': oof_predictions[col].mean(),\n",
    "#                 'Std_Pred': oof_predictions[col].std(),\n",
    "#                 'Min_Pred': oof_predictions[col].min(),\n",
    "#                 'Max_Pred': oof_predictions[col].max()\n",
    "#             }\n",
    "    \n",
    "#     # Create correlation matrix\n",
    "#     print(f\"\\nCorrelation matrix shape: {oof_predictions.corr().shape}\")\n",
    "#     print(f\"Average correlation between models: {oof_predictions.corr().values[np.triu_indices_from(oof_predictions.corr().values, k=1)].mean():.4f}\")\n",
    "    \n",
    "#     return pd.DataFrame(results).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb9f57c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:37:49.246953Z",
     "iopub.status.busy": "2025-05-30T14:37:49.246747Z",
     "iopub.status.idle": "2025-05-30T14:38:15.724472Z",
     "shell.execute_reply": "2025-05-30T14:38:15.723761Z"
    },
    "papermill": {
     "duration": 26.492818,
     "end_time": "2025-05-30T14:38:15.726048",
     "exception": false,
     "start_time": "2025-05-30T14:37:49.233230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_oof_preds.to_csv('xgb_oof_preds.csv', index=False)\n",
    "xgb_test_preds.to_csv('xgb_test_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99c3844a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:38:15.754129Z",
     "iopub.status.busy": "2025-05-30T14:38:15.753897Z",
     "iopub.status.idle": "2025-05-30T14:38:15.757016Z",
     "shell.execute_reply": "2025-05-30T14:38:15.756418Z"
    },
    "papermill": {
     "duration": 0.018332,
     "end_time": "2025-05-30T14:38:15.758276",
     "exception": false,
     "start_time": "2025-05-30T14:38:15.739944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results = analyze_oof_predictions(oof_preds, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e6e97de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:38:15.786247Z",
     "iopub.status.busy": "2025-05-30T14:38:15.786042Z",
     "iopub.status.idle": "2025-05-30T14:38:15.789262Z",
     "shell.execute_reply": "2025-05-30T14:38:15.788566Z"
    },
    "papermill": {
     "duration": 0.017838,
     "end_time": "2025-05-30T14:38:15.790278",
     "exception": false,
     "start_time": "2025-05-30T14:38:15.772440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0600b956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:38:15.817051Z",
     "iopub.status.busy": "2025-05-30T14:38:15.816834Z",
     "iopub.status.idle": "2025-05-30T14:38:15.819922Z",
     "shell.execute_reply": "2025-05-30T14:38:15.819238Z"
    },
    "papermill": {
     "duration": 0.017653,
     "end_time": "2025-05-30T14:38:15.821020",
     "exception": false,
     "start_time": "2025-05-30T14:38:15.803367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scores = cv_score(X_new.drop(columns=['id', 'bmi_hr']), y, model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f86f283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:38:15.849219Z",
     "iopub.status.busy": "2025-05-30T14:38:15.848511Z",
     "iopub.status.idle": "2025-05-30T14:38:15.851919Z",
     "shell.execute_reply": "2025-05-30T14:38:15.851212Z"
    },
    "papermill": {
     "duration": 0.018903,
     "end_time": "2025-05-30T14:38:15.853218",
     "exception": false,
     "start_time": "2025-05-30T14:38:15.834315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33cd9b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:38:15.880768Z",
     "iopub.status.busy": "2025-05-30T14:38:15.880292Z",
     "iopub.status.idle": "2025-05-30T14:38:15.883429Z",
     "shell.execute_reply": "2025-05-30T14:38:15.882908Z"
    },
    "papermill": {
     "duration": 0.01814,
     "end_time": "2025-05-30T14:38:15.884470",
     "exception": false,
     "start_time": "2025-05-30T14:38:15.866330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scores.T.to_csv('model_cv_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36f6b0ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:38:15.911941Z",
     "iopub.status.busy": "2025-05-30T14:38:15.911749Z",
     "iopub.status.idle": "2025-05-30T14:38:15.914622Z",
     "shell.execute_reply": "2025-05-30T14:38:15.914110Z"
    },
    "papermill": {
     "duration": 0.017616,
     "end_time": "2025-05-30T14:38:15.915574",
     "exception": false,
     "start_time": "2025-05-30T14:38:15.897958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scores_df = pd.DataFrame(scores)\n",
    "# scores_df.T.to_csv('models_cv_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67d1fcc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:38:15.942965Z",
     "iopub.status.busy": "2025-05-30T14:38:15.942764Z",
     "iopub.status.idle": "2025-05-30T14:38:15.945895Z",
     "shell.execute_reply": "2025-05-30T14:38:15.945332Z"
    },
    "papermill": {
     "duration": 0.018037,
     "end_time": "2025-05-30T14:38:15.946950",
     "exception": false,
     "start_time": "2025-05-30T14:38:15.928913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cb = cat.CatBoostRegressor(random_state=0, verbose=0, **params)\n",
    "# # etr = ExtraTreesRegressor(random_state=seed, n_jobs=-1)\n",
    "# y_log1p = np.log1p(y)\n",
    "# af = AutoFeatRegressor(feateng_steps=3, verbose=1, n_jobs=1)\n",
    "# X_train_new = af.fit_transform(X, y_log1p)\n",
    "# X_test_new = af.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce01f6a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:38:15.974437Z",
     "iopub.status.busy": "2025-05-30T14:38:15.973912Z",
     "iopub.status.idle": "2025-05-30T14:38:15.976861Z",
     "shell.execute_reply": "2025-05-30T14:38:15.976347Z"
    },
    "papermill": {
     "duration": 0.017608,
     "end_time": "2025-05-30T14:38:15.977969",
     "exception": false,
     "start_time": "2025-05-30T14:38:15.960361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_train_new.to_csv('X_train_new_3step.csv', index=False)\n",
    "# X_test_new.to_csv('X_test_new_3step.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3533676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:38:16.005771Z",
     "iopub.status.busy": "2025-05-30T14:38:16.005104Z",
     "iopub.status.idle": "2025-05-30T14:38:16.008375Z",
     "shell.execute_reply": "2025-05-30T14:38:16.007709Z"
    },
    "papermill": {
     "duration": 0.018296,
     "end_time": "2025-05-30T14:38:16.009387",
     "exception": false,
     "start_time": "2025-05-30T14:38:15.991091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cb.fit(X_train_new, y_log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb8263ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:38:16.036708Z",
     "iopub.status.busy": "2025-05-30T14:38:16.036449Z",
     "iopub.status.idle": "2025-05-30T14:38:16.039635Z",
     "shell.execute_reply": "2025-05-30T14:38:16.038953Z"
    },
    "papermill": {
     "duration": 0.018024,
     "end_time": "2025-05-30T14:38:16.040853",
     "exception": false,
     "start_time": "2025-05-30T14:38:16.022829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # from scipy.special import inv_boxcox\n",
    "# # # # preds_bc = model.predict(X_test_new)\n",
    "# # # # preds = inv_boxcox(preds_bc, lambda_)\n",
    "# preds_log1p = cb.predict(X_test_new)\n",
    "# preds = np.expm1(preds_log1p)\n",
    "# # preds = np.clip(preds, 1, None)\n",
    "# samp_sub['Calories'] = preds\n",
    "# samp_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dfe15aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:38:16.068550Z",
     "iopub.status.busy": "2025-05-30T14:38:16.068345Z",
     "iopub.status.idle": "2025-05-30T14:38:16.078791Z",
     "shell.execute_reply": "2025-05-30T14:38:16.078248Z"
    },
    "papermill": {
     "duration": 0.02575,
     "end_time": "2025-05-30T14:38:16.079957",
     "exception": false,
     "start_time": "2025-05-30T14:38:16.054207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.feature_selection import RFECV\n",
    "# from sklearn.metrics import make_scorer\n",
    "# from sklearn.model_selection import KFold, check_cv\n",
    "# from sklearn.base import BaseEstimator, clone\n",
    "# from sklearn.utils.metaestimators import if_delegate_has_method\n",
    "# from sklearn.utils import check_X_y\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import catboost as cat\n",
    "# from sklearn.metrics import mean_squared_log_error\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# def rmsle(y_true, y_pred):\n",
    "#     \"\"\"Root Mean Squared Logarithmic Error\"\"\"\n",
    "#     # Ensure predictions are positive\n",
    "#     y_pred = np.clip(y_pred, 1e-6, None)\n",
    "#     return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "# class PoolRFECV(RFECV):\n",
    "#     \"\"\"\n",
    "#     Recursive Feature Elimination with Cross-Validation specifically designed for CatBoost\n",
    "#     that uses Pool objects for efficient GPU memory utilization.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, estimator, step=1, min_features_to_select=1, cv=5, \n",
    "#                  scoring=None, verbose=0, n_jobs=None, importance_getter='auto'):\n",
    "        \n",
    "#         super().__init__(\n",
    "#             estimator=estimator,\n",
    "#             step=step,\n",
    "#             min_features_to_select=min_features_to_select,\n",
    "#             cv=cv,\n",
    "#             scoring=scoring,\n",
    "#             verbose=verbose,\n",
    "#             n_jobs=n_jobs,\n",
    "#             importance_getter=importance_getter\n",
    "#         )\n",
    "    \n",
    "#     def _fit(self, X, y, step_score=None):\n",
    "#         \"\"\"\n",
    "#         Custom fit implementation that uses CatBoost Pool objects\n",
    "#         \"\"\"\n",
    "#         # Initial setup similar to parent class\n",
    "#         X, y = check_X_y(X, y, ensure_min_features=2, force_all_finite='allow-nan')\n",
    "        \n",
    "#         # Store the original feature names\n",
    "#         if isinstance(X, pd.DataFrame):\n",
    "#             self.feature_names = X.columns.tolist()\n",
    "#         else:\n",
    "#             self.feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
    "            \n",
    "#         # Setup cross-validation strategy\n",
    "#         cv = check_cv(self.cv, y)\n",
    "        \n",
    "#         # Create the scoring function\n",
    "#         scorer = self.scoring\n",
    "#         if callable(self.scoring):\n",
    "#             scorer = self.scoring\n",
    "#         elif self.scoring is None or isinstance(self.scoring, str):\n",
    "#             scorer = make_scorer(self.scoring)\n",
    "\n",
    "#         # Initialize variables\n",
    "#         n_features = X.shape[1]\n",
    "#         if 0.0 < self.step < 1.0:\n",
    "#             step = int(max(1, self.step * n_features))\n",
    "#         else:\n",
    "#             step = int(self.step)\n",
    "        \n",
    "#         # Create the actual step based on n_features\n",
    "#         if step <= 0:\n",
    "#             raise ValueError(\"Step must be >0\")\n",
    "            \n",
    "#         # Define the number of features to be eliminated in each iteration\n",
    "#         # and determine all possible feature counts\n",
    "#         if step == 1:\n",
    "#             n_feature_subsets = n_features - self.min_features_to_select + 1\n",
    "#         else:\n",
    "#             n_feature_subsets = (n_features - self.min_features_to_select) // step + 1\n",
    "#             if (n_features - self.min_features_to_select) % step > 0:\n",
    "#                 n_feature_subsets += 1\n",
    "                \n",
    "#         # Pre-allocate scores array and support mask\n",
    "#         scores = np.zeros(n_feature_subsets)\n",
    "#         self.cv_results_ = {}\n",
    "        \n",
    "#         # Start with all features\n",
    "#         support_ = np.ones(n_features, dtype=bool)\n",
    "#         ranking_ = np.ones(n_features, dtype=int)\n",
    "        \n",
    "#         # Results containers\n",
    "#         self.cv_results_[\"mean_test_score\"] = np.zeros(n_feature_subsets)\n",
    "#         self.cv_results_[\"std_test_score\"] = np.zeros(n_feature_subsets)\n",
    "        \n",
    "#         # Define a function to evaluate a subset of features\n",
    "#         def _evaluate_subset(train_indices, test_indices, features):\n",
    "#             # Get training and testing data using the specified indices and feature subset\n",
    "#             X_train, X_test = X[train_indices][:, features], X[test_indices][:, features]\n",
    "#             y_train, y_test = y[train_indices], y[test_indices]\n",
    "            \n",
    "#             # Create Pool objects for efficient GPU memory usage\n",
    "#             train_pool = cat.Pool(\n",
    "#                 data=X_train,\n",
    "#                 label=y_train,\n",
    "#                 feature_names=[self.feature_names[i] for i in np.where(features)[0]]\n",
    "#             )\n",
    "            \n",
    "#             test_pool = cat.Pool(\n",
    "#                 data=X_test,\n",
    "#                 label=y_test,\n",
    "#                 feature_names=[self.feature_names[i] for i in np.where(features)[0]]\n",
    "#             )\n",
    "            \n",
    "#             # Clone the estimator to ensure clean fitting\n",
    "#             est = clone(self.estimator)\n",
    "            \n",
    "#             # Fit on train pool\n",
    "#             est.fit(train_pool, verbose=False)\n",
    "            \n",
    "#             # Use fitted estimator to predict test data\n",
    "#             y_pred = est.predict(test_pool)\n",
    "            \n",
    "#             # Return the score\n",
    "#             return scorer._score_func(y_test, y_pred)\n",
    "        \n",
    "#         # Feature subset evaluation\n",
    "#         for feature_subset_idx, feature_subset_size in enumerate(range(n_features, self.min_features_to_select - 1, -step)):\n",
    "#             # Determine features for this subset\n",
    "#             if feature_subset_idx == 0:\n",
    "#                 current_features = np.ones(n_features, dtype=bool)\n",
    "#             else:\n",
    "#                 # Get important features from the current estimator\n",
    "#                 estimator = clone(self.estimator)\n",
    "                \n",
    "#                 # Create a Pool with current features\n",
    "#                 pool = cat.Pool(\n",
    "#                     data=X[:, current_features],\n",
    "#                     label=y,\n",
    "#                     feature_names=[self.feature_names[i] for i in np.where(current_features)[0]]\n",
    "#                 )\n",
    "                \n",
    "#                 # Fit the model\n",
    "#                 estimator.fit(pool, verbose=False)\n",
    "                \n",
    "#                 # Get feature importances\n",
    "#                 if hasattr(estimator, 'feature_importances_'):\n",
    "#                     importances = estimator.feature_importances_\n",
    "#                 elif hasattr(estimator, 'get_feature_importance'):\n",
    "#                     importances = estimator.get_feature_importance()\n",
    "#                 else:\n",
    "#                     raise ValueError(\"Estimator does not have feature_importances_ or get_feature_importance method\")\n",
    "                \n",
    "#                 # Eliminate the least important features\n",
    "#                 # First, we need to ensure indices are relative to the active features\n",
    "#                 active_indices = np.where(current_features)[0]\n",
    "                \n",
    "#                 # Sort by importance but use indices of active features\n",
    "#                 importance_order = np.argsort(importances)\n",
    "                \n",
    "#                 # Calculate number of features to eliminate in this step\n",
    "#                 to_eliminate = min(step, np.sum(current_features) - self.min_features_to_select)\n",
    "                \n",
    "#                 # Update support mask to remove the least important features\n",
    "#                 # Only eliminate up to the number of available features\n",
    "#                 to_eliminate = min(to_eliminate, len(importance_order))\n",
    "                \n",
    "#                 # Get the original indices of features to eliminate\n",
    "#                 for i in range(to_eliminate):\n",
    "#                     if i < len(importance_order):\n",
    "#                         feature_idx = importance_order[i]\n",
    "#                         if feature_idx < len(active_indices):\n",
    "#                             orig_idx = active_indices[feature_idx]\n",
    "#                             current_features[orig_idx] = False\n",
    "            \n",
    "#             # Now evaluate this feature subset using cross-validation\n",
    "#             cv_scores = []\n",
    "            \n",
    "#             # Get split indices\n",
    "#             split_indices = list(cv.split(X, y))\n",
    "            \n",
    "#             # Evaluate the current feature subset using parallel processing if required\n",
    "#             if self.n_jobs and self.n_jobs != 1:\n",
    "#                 cv_scores = Parallel(n_jobs=self.n_jobs)(\n",
    "#                     delayed(_evaluate_subset)(\n",
    "#                         train_indices, test_indices, current_features\n",
    "#                     )\n",
    "#                     for train_indices, test_indices in split_indices\n",
    "#                 )\n",
    "#             else:\n",
    "#                 for train_indices, test_indices in split_indices:\n",
    "#                     cv_scores.append(_evaluate_subset(train_indices, test_indices, current_features))\n",
    "            \n",
    "#             # Calculate mean and std of scores\n",
    "#             mean_score = np.mean(cv_scores)\n",
    "#             std_score = np.std(cv_scores)\n",
    "            \n",
    "#             # Store the results\n",
    "#             self.cv_results_[\"mean_test_score\"][feature_subset_idx] = mean_score\n",
    "#             self.cv_results_[\"std_test_score\"][feature_subset_idx] = std_score\n",
    "            \n",
    "#             # If this is the first subset, no need to compare with previous\n",
    "#             if feature_subset_idx == 0:\n",
    "#                 best_subset_size = feature_subset_size\n",
    "#                 best_subset_idx = feature_subset_idx\n",
    "#             # Otherwise, check if current subset is better than the best so far\n",
    "#             elif mean_score > self.cv_results_[\"mean_test_score\"][best_subset_idx]:\n",
    "#                 best_subset_size = feature_subset_size\n",
    "#                 best_subset_idx = feature_subset_idx\n",
    "            \n",
    "#             # Print progress if verbose\n",
    "#             if self.verbose > 0:\n",
    "#                 print(f\"Features: {np.sum(current_features)}/{n_features} - Score: {mean_score:.4f} ± {std_score:.4f}\")\n",
    "            \n",
    "#             # Update support and ranking\n",
    "#             ranking_[~current_features] = n_features - np.sum(current_features) + 1\n",
    "            \n",
    "#             # Check if we've reached the minimum features to select\n",
    "#             if np.sum(current_features) <= self.min_features_to_select:\n",
    "#                 break\n",
    "        \n",
    "#         # Find the subset with the best score\n",
    "#         best_idx = np.argmax(self.cv_results_[\"mean_test_score\"])\n",
    "        \n",
    "#         # If the best score is not from the first subset, go back and determine which features to keep\n",
    "#         if best_idx > 0:\n",
    "#             # Start with all features\n",
    "#             temp_support = np.ones(n_features, dtype=bool)\n",
    "            \n",
    "#             # Recreate the elimination process to determine the best subset\n",
    "#             for feature_subset_idx in range(best_idx):\n",
    "#                 # Create a Pool with current features\n",
    "#                 estimator = clone(self.estimator)\n",
    "                \n",
    "#                 # Get indices where features are active\n",
    "#                 active_indices = np.where(temp_support)[0]\n",
    "                \n",
    "#                 pool = cat.Pool(\n",
    "#                     data=X[:, temp_support],\n",
    "#                     label=y,\n",
    "#                     feature_names=[self.feature_names[i] for i in active_indices]\n",
    "#                 )\n",
    "                \n",
    "#                 # Fit the model\n",
    "#                 estimator.fit(pool, verbose=False)\n",
    "                \n",
    "#                 # Get feature importances\n",
    "#                 if hasattr(estimator, 'feature_importances_'):\n",
    "#                     importances = estimator.feature_importances_\n",
    "#                 elif hasattr(estimator, 'get_feature_importance'):\n",
    "#                     importances = estimator.get_feature_importance()\n",
    "#                 else:\n",
    "#                     raise ValueError(\"Estimator does not have feature_importances_ or get_feature_importance method\")\n",
    "                \n",
    "#                 # Sort features by importance (ascending)\n",
    "#                 importance_order = np.argsort(importances)\n",
    "                \n",
    "#                 # Calculate number of features to eliminate in this step\n",
    "#                 to_eliminate = min(step, np.sum(temp_support) - self.min_features_to_select)\n",
    "                \n",
    "#                 # Only eliminate up to the number of available features\n",
    "#                 to_eliminate = min(to_eliminate, len(importance_order))\n",
    "                \n",
    "#                 # Update support mask to remove the least important features\n",
    "#                 for i in range(to_eliminate):\n",
    "#                     if i < len(importance_order):\n",
    "#                         feature_idx = importance_order[i]\n",
    "#                         if feature_idx < len(active_indices):\n",
    "#                             orig_idx = active_indices[feature_idx]\n",
    "#                             temp_support[orig_idx] = False\n",
    "            \n",
    "#             # Set the final support and ranking\n",
    "#             self.support_ = temp_support\n",
    "            \n",
    "#         else:\n",
    "#             # If the best is the first subset with all features, support is already all ones\n",
    "#             self.support_ = np.ones(n_features, dtype=bool)\n",
    "        \n",
    "#         # Update ranking based on final support\n",
    "#         self.ranking_ = np.ones(n_features, dtype=int)\n",
    "#         self.ranking_[~self.support_] = 2  # 1 for selected, 2 for not selected (simple ranking)\n",
    "        \n",
    "#         # Store the optimal number of features\n",
    "#         self.n_features_ = np.sum(self.support_)\n",
    "        \n",
    "#         # Final fit with selected features\n",
    "#         self.estimator_ = clone(self.estimator)\n",
    "        \n",
    "#         pool = cat.Pool(\n",
    "#             data=X[:, self.support_],\n",
    "#             label=y,\n",
    "#             feature_names=[self.feature_names[i] for i in np.where(self.support_)[0]]\n",
    "#         )\n",
    "        \n",
    "#         self.estimator_.fit(pool, verbose=False)\n",
    "        \n",
    "#         return self\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         \"\"\"\n",
    "#         Fit the RFE model with CatBoost Pool optimization.\n",
    "        \n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : array-like of shape (n_samples, n_features)\n",
    "#             Training data.\n",
    "#         y : array-like of shape (n_samples,)\n",
    "#             Target values.\n",
    "        \n",
    "#         Returns\n",
    "#         -------\n",
    "#         self : object\n",
    "#             Returns the instance itself.\n",
    "#         \"\"\"\n",
    "#         return self._fit(X, y)\n",
    "    \n",
    "#     @if_delegate_has_method(['estimator', 'estimator_'])\n",
    "#     def predict(self, X):\n",
    "#         \"\"\"Reduce X to the selected features and predict using the estimator.\"\"\"\n",
    "#         # Convert data to numpy if not already\n",
    "#         X_numpy = X.values if isinstance(X, pd.DataFrame) else X\n",
    "        \n",
    "#         # Create Pool for prediction\n",
    "#         pool = cat.Pool(\n",
    "#             data=X_numpy[:, self.support_],\n",
    "#             feature_names=[self.feature_names[i] for i in np.where(self.support_)[0]]\n",
    "#         )\n",
    "        \n",
    "#         return self.estimator_.predict(pool)\n",
    "\n",
    "# def rfecv_feature_selector(X_transformed, y_target, model, n_splits=5, seed=42):\n",
    "#     \"\"\"\n",
    "#     RFECV feature selection with CatBoost Pool integration for GPU memory optimization\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     X_transformed : pandas.DataFrame\n",
    "#         The feature matrix\n",
    "#     y_target : pandas.Series\n",
    "#         The target variable\n",
    "#     model : CatBoostRegressor\n",
    "#         The CatBoost model to use for feature selection\n",
    "#     n_splits : int, default=5\n",
    "#         Number of CV folds\n",
    "#     seed : int, default=42\n",
    "#         Random seed for reproducibility\n",
    "    \n",
    "#     Returns\n",
    "#     -------\n",
    "#     tuple : (best_score, best_features)\n",
    "#         The best CV score and the list of selected features\n",
    "#     \"\"\"\n",
    "#     # Define a custom scoring function for RMSLE - fixed to handle log-transformed targets\n",
    "#     def _custom_rmsle(y_true_log, y_pred_log):\n",
    "#         \"\"\"\n",
    "#         Calculate RMSLE after converting predictions from log space back to original space\n",
    "        \n",
    "#         Parameters:\n",
    "#         -----------\n",
    "#         y_true_log : array-like\n",
    "#             Log-transformed true target values used during training\n",
    "#         y_pred_log : array-like\n",
    "#             Log-transformed predictions from the model\n",
    "            \n",
    "#         Returns:\n",
    "#         --------\n",
    "#         float : Negative RMSLE score (negative because sklearn maximizes scores)\n",
    "#         \"\"\"\n",
    "#         # Convert both true values and predictions back from log space\n",
    "#         y_true_orig = np.expm1(y_true_log)\n",
    "#         y_pred_orig = np.expm1(y_pred_log)\n",
    "        \n",
    "#         # Apply min clip to predictions to avoid negative values\n",
    "#         y_pred_orig = np.clip(y_pred_orig, 1e-6, None)\n",
    "        \n",
    "#         # Calculate RMSLE in original space\n",
    "#         score = rmsle(y_true_orig, y_pred_orig)\n",
    "        \n",
    "#         # CHANGE: Store the raw RMSLE score without negation\n",
    "#         # We'll handle the negation separately for sklearn\n",
    "#         return score\n",
    "    \n",
    "#     # CHANGE: Create scorer with greater_is_better=False to avoid negation in the scoring function\n",
    "#     custom_scorer = make_scorer(_custom_rmsle, greater_is_better=False)\n",
    "    \n",
    "#     # 1. Log transform target for CatBoost\n",
    "#     y_log = np.log1p(y_target)\n",
    "    \n",
    "#     # 2. Configure RFECV with our custom Pool-optimized implementation\n",
    "#     selector = PoolRFECV(\n",
    "#         estimator=model,\n",
    "#         step=1,  # Remove multiple features at each step\n",
    "#         cv=KFold(n_splits, shuffle=True, random_state=seed),\n",
    "#         scoring=custom_scorer,\n",
    "#         min_features_to_select=16,\n",
    "#         n_jobs=1,  # Set to 1 for GPU memory optimization\n",
    "#         verbose=1\n",
    "#     )\n",
    "    \n",
    "#     # 3. Convert DataFrame to NumPy arrays for our custom RFECV implementation\n",
    "#     X_numpy = X_transformed.values if isinstance(X_transformed, pd.DataFrame) else X_transformed\n",
    "    \n",
    "#     # 4. Feature elimination with Pool optimization\n",
    "#     selector.fit(X_numpy, y_log)\n",
    "    \n",
    "#     # 5. Get selected features\n",
    "#     feature_names = X_transformed.columns.tolist()\n",
    "#     best_features = [feature_names[i] for i in range(len(feature_names)) if selector.support_[i]]\n",
    "    \n",
    "#     # 6. CHANGED: Get the best score directly since we're using greater_is_better=False\n",
    "#     # This means the minimum score in cv_results is the best one\n",
    "#     if len(selector.cv_results_['mean_test_score']) > 0:\n",
    "#         # Now we get the minimum since lower RMSLE is better and greater_is_better=False\n",
    "#         best_score = np.min(selector.cv_results_['mean_test_score'])\n",
    "        \n",
    "#         # Debug lines (remove in production)\n",
    "#         print(\"Raw CV results scores:\", selector.cv_results_['mean_test_score'])\n",
    "#         print(\"Best index:\", np.argmin(selector.cv_results_['mean_test_score']))\n",
    "#         print(\"Min raw score (should be positive RMSLE):\", best_score)\n",
    "        \n",
    "#         # Ensure score is never shown as exactly 0.0 if it's a small but real value\n",
    "#         if 0 < best_score < 0.00001:\n",
    "#             best_score = max(0.00001, best_score)\n",
    "#     else:\n",
    "#         best_score = float('inf')  # Default if no scores available\n",
    "    \n",
    "#     return best_score, best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdf9f434",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:38:16.108043Z",
     "iopub.status.busy": "2025-05-30T14:38:16.107835Z",
     "iopub.status.idle": "2025-05-30T14:38:16.111224Z",
     "shell.execute_reply": "2025-05-30T14:38:16.110477Z"
    },
    "papermill": {
     "duration": 0.018688,
     "end_time": "2025-05-30T14:38:16.112386",
     "exception": false,
     "start_time": "2025-05-30T14:38:16.093698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_score, selected_features = rfecv_feature_selector(\n",
    "#     X_transformed=X_train_new,\n",
    "#     y_target=y,\n",
    "#     model=model,\n",
    "#     n_splits=5,\n",
    "#     seed=42\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b8ba360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:38:16.139529Z",
     "iopub.status.busy": "2025-05-30T14:38:16.139347Z",
     "iopub.status.idle": "2025-05-30T14:38:16.143059Z",
     "shell.execute_reply": "2025-05-30T14:38:16.142266Z"
    },
    "papermill": {
     "duration": 0.01824,
     "end_time": "2025-05-30T14:38:16.144052",
     "exception": false,
     "start_time": "2025-05-30T14:38:16.125812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9716510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T14:38:16.171416Z",
     "iopub.status.busy": "2025-05-30T14:38:16.171220Z",
     "iopub.status.idle": "2025-05-30T14:38:16.174215Z",
     "shell.execute_reply": "2025-05-30T14:38:16.173710Z"
    },
    "papermill": {
     "duration": 0.017928,
     "end_time": "2025-05-30T14:38:16.175223",
     "exception": false,
     "start_time": "2025-05-30T14:38:16.157295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f02a0",
   "metadata": {
    "papermill": {
     "duration": 0.012776,
     "end_time": "2025-05-30T14:38:16.201179",
     "exception": false,
     "start_time": "2025-05-30T14:38:16.188403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11893428,
     "sourceId": 91716,
     "sourceType": "competition"
    },
    {
     "sourceId": 242202915,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13673.969309,
   "end_time": "2025-05-30T14:38:18.773878",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-30T10:50:24.804569",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
