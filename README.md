# Kaggle Playground Series (S4 + S5)

This repository contains my complete participation in the **Kaggle Playground Series (Season 4 & 5)**. Each folder contains my experiments, notebooks, and approaches for the corresponding episode. Most notebooks are complete E2E pipelines, ranging from baseline models to AutoML/Optuna optimization, ensemble learning, and model stacking.

>  I participated in over **13 Playground Competitions** and still counting, consistently placing in the top 10‚Äì20% in many of them.

---

##  Highlights

| Season | Episode | Challenge Title                                | Type           | Rank         | Teams | Percentile | Metric                                      |
|:------:|:--------|:-----------------------------------------------|:---------------|:-------------|------:|-----------:|:---------------------------------------------|
| S4     | E11     | Exploring Mental Health Data                   | Classification | 35 / 2685    | 2685  | Top 1.3%   | Accuracy                                     |
| S5     | E2      | Backpack Prediction Challenge                  | Classification | 202 / 3393   | 3393  | Top 5.9%   | Root Mean Squared Error (RMSE)              |
| S5     | E5      | Predict Calorie Expenditure                    | Regression     | 375 / 4316   | 4316  | Top 8.6%   | Root Mean Squared Logarithmic Error (RMSLE) |
| S5     | E6      | Predicting Optimal Fertilizers                 | Classification | 274 / 2648   | 2648  | Top 10.3%  | Mean Average Precision @ 3 (MAP@3)          |
| S4     | E10     | Loan Approval Prediction                       | Classification | 474 / 3858   | 3858  | Top 12.2%  | Area Under the ROC Curve                    |
| S5     | E1      | Forecasting Sticker Sales                      | Forecasting    | 468 / 2722   | 2722  | Top 17.2%  | Mean Absolute Percentage Error (MAPE)       |
| S4     | E8      | Binary Prediction of Poisonous Mushrooms      | Classification | 459 / 2422   | 2422  | Top 18.9%  | Matthews Correlation Coefficient (MCC)      |
| S4     | E7      | Insurance Cross-Selling                        | Classification | 472 / 2234   | 2234  | Top 21.1%  | Area Under the ROC Curve                    |
| S4     | E6      | Academic Success Classification                | Classification | 587 / 2684   | 2684  | Top 21.9%  | Accuracy                                     |
| S5     | E4      | Predict Podcast Listening Time                 | Regression     | 878 / 3310   | 3310  | Top 26.5%  | Root Mean Squared Error (RMSE)              |
| S5     | E3      | Binary Prediction with Rainfall                | Classification | 1327 / 4381  | 4381  | Top 30.3%  | Area Under the ROC Curve                    |
| S4     | E5      | Regression with Flood Prediction               | Regression     | 985 / 2788   | 2788  | Top 35.3%  | R2 Score                                     |
| S4     | E9      | Regression of Used Car Prices                  | Regression     | 1337 / 3066  | 3066  | Top 43.6%  | Root Mean Squared Error (RMSE)              |


---

## üîç Contents

Each subfolder contains:
- ‚úÖ `EDA.ipynb`: Initial Exploratory Analysis
- ‚öôÔ∏è `model_x.ipynb`: Model training and evaluation
- üìä `optuna.ipynb` or `automl.ipynb`: Hyperparameter tuning
- üß† `README.md`: Short description of the competition, approach used, and final rank.

---

## üîß Tools Used

- Python, Pandas, Scikit-Learn, XGBoost, LightGBM, CatBoost
- AutoGluon, H2O AutoML, Optuna
- Ensemble Modeling, Feature Engineering, Cross Validation
- SHAP for model explainability
